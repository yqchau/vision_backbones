import argparse

import pandas as pd
import torch

from models.timm_models import create_timm_models
from utils.inference import calc_memory


def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--initial-benchmark-path",
        type=str,
        default="./results/full.csv",
        help="Path to CSV File Generated by benchmark.py",
    )
    parser.add_argument(
        "--model-type",
        type=str,
        default="torch_speed_fp32",
        help="Name of Column to Calculate Accuracy",
    )
    parser.add_argument(
        "--metric-name",
        type=str,
        default="memory",
        help="Name of Accuracy Column",
    )
    parser.add_argument(
        "--final-benchmark-path",
        type=str,
        default="./benchmark_list.csv",
        help="Final Benchmark File Location",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1,
        help="batch size",
    )
    parser.add_argument(
        "--channels",
        type=int,
        default=3,
        help="Number of channels of input image",
    )
    parser.add_argument(
        "--image-width",
        type=int,
        default=224,
        help="Image Width",
    )
    parser.add_argument(
        "--image-height",
        type=int,
        default=224,
        help="Image Height",
    )
    parser.add_argument(
        "--gpu-id",
        type=int,
        default=0,
        help="GPU id, either 0,1,2 or 3",
    )
    parser.add_argument(
        "--classes",
        type=int,
        default=1000,
        help="Number of classes",
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=500,
        help="Number of samples",
    )
    parser.add_argument(
        "--i",
        type=int,
        default=0,
        help="index of model",
    )

    return parser.parse_args()


def gpu_main(opt):
    batch_size = opt.batch_size
    channels = opt.channels
    img_height = opt.image_height
    img_width = opt.image_width
    gpu_id = opt.gpu_id
    device = torch.device("cuda")
    classes = opt.classes
    num_samples = opt.num_samples
    metric_name = opt.metric_name
    final_benchmark_path = opt.final_benchmark_path

    benchmark_df = pd.read_csv(opt.final_benchmark_path)
    benchmark_df[benchmark_df[opt.model_type].notnull()]
    i = opt.i

    model_name = benchmark_df.at[i, "model"]
    try:
        dummy_inputs = torch.ones(batch_size, channels, img_height, img_width).to(
            device
        )
        model = (
            create_timm_models(
                arch=model_name,
                classes=classes,
                transfer_learning=False,
            )
            .eval()
            .to(device)
        )
        mem_used = calc_memory(
            model=model, inputs=dummy_inputs, num_samples=num_samples, gpu_id=gpu_id
        )
        benchmark_df.at[i, metric_name] = mem_used
        benchmark_df.to_csv(final_benchmark_path, index=False)

    except AssertionError as e:
        print("something went wrong")
        raise e


if __name__ == "__main__":
    opt = parse_opt()
    gpu_main(opt)
